"""
Enhanced CSV Parser Module
æ–°ã‚¹ã‚­ãƒ¼ãƒå¯¾å¿œãƒ»ä¸¡æ–¹ã®çœŸå®Ÿä¿æŒç‰ˆCSVãƒ‘ãƒ¼ã‚µãƒ¼
"""

import csv
import io
import logging
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime

# pandaså•é¡Œã‚’å›é¿ã™ã‚‹ãŸã‚ã€ãƒ†ã‚¹ãƒˆæ™‚ã¯å˜ç´”ãªCSVå‡¦ç†ã‚’ä½¿ç”¨
try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False
    print("âš ï¸  pandasåˆ©ç”¨ä¸å¯ - å˜ç´”ãªCSVå‡¦ç†ã‚’ä½¿ç”¨")

try:
    from .database_manager import DatabaseManager
    from .symbol_utils import SymbolNormalizer, DecimalFormatter
except ImportError:
    from database_manager import DatabaseManager
    from symbol_utils import SymbolNormalizer, DecimalFormatter

logger = logging.getLogger(__name__)


class EnhancedCSVParser:
    """æ–°ã‚¹ã‚­ãƒ¼ãƒå¯¾å¿œçµ±ä¸€CSVãƒ‘ãƒ¼ã‚µãƒ¼"""
    
    def __init__(self, db_manager: Optional[DatabaseManager] = None):
        """
        Args:
            db_manager: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
        """
        self.db_manager = db_manager or DatabaseManager()
        self.symbol_normalizer = SymbolNormalizer()
        self.decimal_formatter = DecimalFormatter()
        
        # è¨¼åˆ¸ä¼šç¤¾åˆ¥ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°
        self.field_mappings = {
            'sbi': {
                'symbol_fields': ['éŠ˜æŸ„ï¼ˆã‚³ãƒ¼ãƒ‰ï¼‰', 'éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰'],
                'name_fields': ['éŠ˜æŸ„åç§°', 'éŠ˜æŸ„å'],
                'quantity_fields': ['æ•°é‡', 'ä¿æœ‰æ•°é‡', 'ä¿æœ‰æ ªæ•°'],
                'average_price_fields': ['å–å¾—å˜ä¾¡', 'å¹³å‡å–å¾—ä¾¡æ ¼'],
                'current_price_fields': ['ç¾åœ¨å€¤'],
                'market_value_fields': ['è©•ä¾¡é¡'],
                'profit_loss_fields': ['æç›Š', 'è©•ä¾¡æç›Š'],
                'profit_loss_percent_fields': ['æç›Šï¼ˆï¼…ï¼‰', 'æç›Šç‡'],
            },
            'rakuten': {
                'symbol_fields': ['éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰', 'éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ãƒ»ãƒ†ã‚£ãƒƒã‚«ãƒ¼'],
                'name_fields': ['éŠ˜æŸ„å', 'éŠ˜æŸ„'],
                'quantity_fields': ['ä¿æœ‰æ•°é‡ï¼»æ ªï¼½', 'ä¿æœ‰æ•°é‡'],
                'average_price_fields': ['å¹³å‡å–å¾—ä¾¡é¡ï¼»å††ï¼½', 'å¹³å‡å–å¾—ä¾¡é¡'],
                'current_price_fields': ['ç¾åœ¨å€¤ï¼»å††ï¼½', 'ç¾åœ¨å€¤'],
                'market_value_fields': ['æ™‚ä¾¡è©•ä¾¡é¡ï¼»å††ï¼½', 'æ™‚ä¾¡è©•ä¾¡é¡[å††]'],
                'profit_loss_fields': ['è©•ä¾¡æç›Šï¼»å††ï¼½', 'è©•ä¾¡æç›Š[å††]'],
                'total_cost_fields': ['å–å¾—ç·é¡ï¼»å††ï¼½'],
            }
        }
    
    def parse_csv_to_database(self, file_content: bytes, filename: str, 
                             data_source: Optional[str] = None) -> Tuple[bool, Dict[str, Any]]:
        """
        CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã¦ç›´æ¥ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
        
        Args:
            file_content: CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹
            filename: ãƒ•ã‚¡ã‚¤ãƒ«å
            data_source: ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ï¼ˆè‡ªå‹•åˆ¤å®šå¯èƒ½ï¼‰
            
        Returns:
            Tuple[æˆåŠŸãƒ•ãƒ©ã‚°, å‡¦ç†çµæœ]
        """
        try:
            # CSVèª­ã¿è¾¼ã¿
            lines, encoding = self._read_csv_with_encoding(file_content)
            logger.info(f"CSVèª­ã¿è¾¼ã¿: {filename}, ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°: {encoding}, è¡Œæ•°: {len(lines)}")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹è‡ªå‹•åˆ¤å®š
            if data_source is None:
                data_source = self._detect_data_source(lines, filename)
            
            logger.info(f"æ¤œå‡ºã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {data_source}")
            
            # ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã¨æ­£è¦åŒ–
            portfolio_data = self._extract_portfolio_data(lines, data_source)
            
            if not portfolio_data:
                return False, {"error": "æœ‰åŠ¹ãªãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
            success_count = 0
            error_count = 0
            
            for item in portfolio_data:
                if self.db_manager.insert_portfolio_data(item):
                    success_count += 1
                else:
                    error_count += 1
            
            result = {
                "data_source": data_source,
                "total_records": len(portfolio_data),
                "success_count": success_count,
                "error_count": error_count,
                "encoding": encoding
            }
            
            logger.info(f"CSVå‡¦ç†å®Œäº†: {success_count}ä»¶æˆåŠŸ, {error_count}ä»¶å¤±æ•—")
            return success_count > 0, result
            
        except Exception as e:
            logger.error(f"CSVå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return False, {"error": str(e)}
    
    def _read_csv_with_encoding(self, file_content: bytes) -> Tuple[List[List[str]], str]:
        """è¤‡æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§CSVèª­ã¿è¾¼ã¿ï¼ˆpandasä¸ä½¿ç”¨ç‰ˆï¼‰"""
        encodings = ['utf-8', 'shift_jis', 'cp932', 'utf-8-sig']
        
        for encoding in encodings:
            try:
                content = file_content.decode(encoding)
                
                # CSVèª­ã¿è¾¼ã¿ï¼ˆæ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½¿ç”¨ï¼‰
                lines = []
                reader = csv.reader(io.StringIO(content))
                for row in reader:
                    lines.append(row)
                
                logger.debug(f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° {encoding} ã§èª­ã¿è¾¼ã¿æˆåŠŸ: {len(lines)}è¡Œ")
                return lines, encoding
                
            except UnicodeDecodeError as e:
                logger.debug(f"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° {encoding} ã§å¤±æ•—: {e}")
                continue
        
        raise ValueError("ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã™")
    
    def _detect_data_source(self, lines: List[List[str]], filename: str) -> str:
        """ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ï¼ˆè¨¼åˆ¸ä¼šç¤¾ï¼‰ã®è‡ªå‹•åˆ¤å®š"""
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰åˆ¤å®š
        filename_lower = filename.lower()
        if 'assetbalance' in filename_lower:
            return 'rakuten'
        elif 'savefile' in filename_lower or 'new_file' in filename_lower:
            return 'sbi'
        
        # å†…å®¹ã‹ã‚‰åˆ¤å®š
        content_str = ' '.join([' '.join(row) for row in lines])
        
        # æ¥½å¤©è¨¼åˆ¸ã®ç‰¹å¾´çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³
        if any(pattern in content_str for pattern in [
            'ä¿æœ‰å•†å“è©³ç´°', 'â– ç‰¹å®šå£åº§', 'â– NISAæˆé•·æŠ•è³‡æ ', 
            'å¹³å‡å–å¾—ä¾¡é¡ï¼»å††ï¼½', 'æ™‚ä¾¡è©•ä¾¡é¡ï¼»å††ï¼½'
        ]):
            return 'rakuten'
        
        # SBIè¨¼åˆ¸ã®ç‰¹å¾´çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³
        elif any(pattern in content_str for pattern in [
            'ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªä¸€è¦§', 'éŠ˜æŸ„ï¼ˆã‚³ãƒ¼ãƒ‰ï¼‰', 'å–å¾—å˜ä¾¡', 'æç›Šï¼ˆï¼…ï¼‰'
        ]):
            return 'sbi'
        
        return 'unknown'
    
    def _extract_portfolio_data(self, lines: List[List[str]], data_source: str) -> List[Dict[str, Any]]:
        """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºãƒ»æ­£è¦åŒ–"""
        if data_source == 'rakuten':
            return self._extract_rakuten_data(lines)
        elif data_source == 'sbi':
            return self._extract_sbi_data(lines)
        else:
            logger.warning(f"æœªå¯¾å¿œã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {data_source}")
            return []
    
    def _extract_sbi_data(self, lines: List[List[str]]) -> List[Dict[str, Any]]:
        """SBIè¨¼åˆ¸ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º"""
        portfolio_data = []
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’æ¢ã™
        header_row_idx = None
        for idx, row in enumerate(lines):
            row_str = ' '.join(str(cell) for cell in row)
            if 'éŠ˜æŸ„ï¼ˆã‚³ãƒ¼ãƒ‰ï¼‰' in row_str and 'æ•°é‡' in row_str:
                header_row_idx = idx
                break
        
        if header_row_idx is None:
            logger.error("SBIè¨¼åˆ¸ã®ãƒ˜ãƒƒãƒ€ãƒ¼è¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return []
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’å–å¾—
        headers = [str(cell).strip() for cell in lines[header_row_idx]]
        
        # ãƒ‡ãƒ¼ã‚¿è¡Œã‚’å‡¦ç†
        for idx in range(header_row_idx + 1, len(lines)):
            row = lines[idx]
            if not row or all(not cell.strip() for cell in row):
                continue
            
            # è¡Œãƒ‡ãƒ¼ã‚¿ã‚’è¾æ›¸ã«å¤‰æ›
            row_dict = {}
            for i, value in enumerate(row):
                if i < len(headers) and headers[i]:
                    row_dict[headers[i]] = value
            
            # éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            item = self._extract_stock_item(row_dict, 'sbi')
            if item:
                portfolio_data.append(item)
        
        return portfolio_data
    
    def _extract_rakuten_data(self, lines: List[List[str]]) -> List[Dict[str, Any]]:
        """æ¥½å¤©è¨¼åˆ¸ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º"""
        portfolio_data = []
        
        # è¤‡æ•°ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆç‰¹å®šå£åº§ã€NISAç­‰ï¼‰ã‚’å‡¦ç†
        for idx, row in enumerate(lines):
            row_str = ' '.join(str(cell) for cell in row)
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’æ¤œå‡º
            if 'éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰' in row_str and 'ä¿æœ‰æ•°é‡ï¼»æ ªï¼½' in row_str:
                headers = [str(cell).strip().strip('\"') for cell in row]
                
                # ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                section_data = self._extract_rakuten_section(lines, idx, headers)
                portfolio_data.extend(section_data)
        
        return portfolio_data
    
    def _extract_rakuten_section(self, lines: List[List[str]], header_idx: int, 
                                headers: List[str]) -> List[Dict[str, Any]]:
        """æ¥½å¤©è¨¼åˆ¸ã®ç‰¹å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        section_data = []
        
        # ãƒ‡ãƒ¼ã‚¿è¡Œã®ç¯„å›²ã‚’ç‰¹å®š
        data_start = header_idx + 1
        data_end = len(lines)
        
        for idx in range(data_start, data_end):
            row = lines[idx]
            row_str = ' '.join(str(cell) for cell in row)
            
            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³çµ‚äº†ã®åˆ¤å®š
            if ('åˆè¨ˆ' in row_str and 'å£åº§åˆè¨ˆ' in row_str) or 'â– ' in row_str:
                break
            
            # ç©ºè¡Œã‚¹ã‚­ãƒƒãƒ—
            if not row or all(not cell.strip() for cell in row):
                continue
            
            # è¡Œãƒ‡ãƒ¼ã‚¿ã‚’è¾æ›¸ã«å¤‰æ›
            row_dict = {}
            for i, value in enumerate(row):
                if i < len(headers) and headers[i]:
                    row_dict[headers[i]] = str(value).strip().strip('\"')
            
            # éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
            item = self._extract_stock_item(row_dict, 'rakuten')
            if item:
                section_data.append(item)
        
        return section_data
    
    def _extract_stock_item(self, row_dict: Dict[str, Any], data_source: str) -> Optional[Dict[str, Any]]:
        """å€‹åˆ¥éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºãƒ»æ­£è¦åŒ–"""
        try:
            # éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã¨éŠ˜æŸ„åã‚’æŠ½å‡º
            symbol, name = self.symbol_normalizer.extract_symbols_from_csv_row(row_dict)
            
            if not symbol:
                return None
            
            # åŸºæœ¬ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
            mappings = self.field_mappings.get(data_source, {})
            
            # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºã¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            quantity = self._extract_numeric_value(row_dict, mappings.get('quantity_fields', []))
            average_price = self._extract_numeric_value(row_dict, mappings.get('average_price_fields', []))
            current_price = self._extract_numeric_value(row_dict, mappings.get('current_price_fields', []))
            market_value = self._extract_numeric_value(row_dict, mappings.get('market_value_fields', []))
            profit_loss = self._extract_numeric_value(row_dict, mappings.get('profit_loss_fields', []))
            
            # æç›Šç‡ã®å‡¦ç†ï¼ˆä¸¡æ–¹ã®çœŸå®Ÿã‚’ä¿æŒï¼‰
            profit_loss_percent_original = self._extract_numeric_value(
                row_dict, mappings.get('profit_loss_percent_fields', [])
            )
            
            # SBIè¨¼åˆ¸ã®æç›Šç‡ã¯%å€¤ã€æ¥½å¤©è¨¼åˆ¸ã¯è¨ˆç®—
            if data_source == 'sbi' and profit_loss_percent_original is not None:
                # SBI: 167.98% â†’ percent=167.9, decimal=1.679
                profit_loss_rate_percent = self.decimal_formatter.format_percentage(profit_loss_percent_original)
                profit_loss_rate_decimal = round(profit_loss_percent_original / 100.0, 4)
            elif data_source == 'rakuten' and average_price and current_price:
                # æ¥½å¤©: è¨ˆç®—ã§æç›Šç‡ã‚’ç®—å‡º
                rate_decimal = (current_price - average_price) / average_price
                profit_loss_rate_percent = self.decimal_formatter.format_percentage(rate_decimal * 100)
                profit_loss_rate_decimal = round(rate_decimal, 4)
                profit_loss_percent_original = None  # æ¥½å¤©è¨¼åˆ¸ã«ã¯ãªã„
            else:
                profit_loss_rate_percent = None
                profit_loss_rate_decimal = None
            
            # å–å¾—ç·é¡ã®è¨ˆç®—ï¼ˆæ¥½å¤©è¨¼åˆ¸ã‹ã‚‰å–å¾—ã¾ãŸã¯è¨ˆç®—ï¼‰
            total_cost = self._extract_numeric_value(row_dict, mappings.get('total_cost_fields', []))
            if total_cost is None and quantity and average_price:
                total_cost = self.decimal_formatter.format_price(quantity * average_price)
            
            # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®æ§‹ç¯‰
            item = {
                'symbol': symbol,
                'name': name,
                'data_source': data_source,
                'quantity': int(quantity) if quantity else 0,
                'average_price': self.decimal_formatter.format_price(average_price),
                'current_price': self.decimal_formatter.format_price(current_price),
                'market_value': self.decimal_formatter.format_price(market_value),
                'profit_loss': self.decimal_formatter.format_price(profit_loss),
                'total_cost': total_cost,
                'profit_loss_rate_original': profit_loss_percent_original,
                'profit_loss_rate_percent': profit_loss_rate_percent,
                'profit_loss_rate_decimal': profit_loss_rate_decimal
            }
            
            logger.debug(f"éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿æŠ½å‡º: {symbol} ({data_source}) - æç›Šç‡: {profit_loss_rate_percent}%")
            return item
            
        except Exception as e:
            logger.error(f"éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _extract_numeric_value(self, row_dict: Dict[str, Any], field_candidates: List[str]) -> Optional[float]:
        """æ•°å€¤ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŠ½å‡º"""
        for field in field_candidates:
            if field in row_dict and row_dict[field]:
                value_str = str(row_dict[field]).strip().replace(',', '').replace('+', '')
                try:
                    return float(value_str)
                except ValueError:
                    continue
        return None
    
    def get_portfolio_summary(self) -> Dict[str, Any]:
        """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚µãƒãƒªãƒ¼ã‚’å–å¾—"""
        try:
            analytics = self.db_manager.get_portfolio_analytics()
            
            if not analytics:
                return {"error": "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"}
            
            # ã‚µãƒãƒªãƒ¼è¨ˆç®—
            total_market_value = sum(item.get('market_value', 0) or 0 for item in analytics)
            total_profit_loss = sum(item.get('profit_loss', 0) or 0 for item in analytics)
            
            summary = {
                "total_holdings": len(analytics),
                "total_market_value": total_market_value,
                "total_profit_loss": total_profit_loss,
                "profit_loss_rate": (total_profit_loss / (total_market_value - total_profit_loss) * 100) 
                                   if (total_market_value - total_profit_loss) > 0 else 0,
                "data_sources": list(set(item.get('data_source') for item in analytics if item.get('data_source'))),
                "last_updated": max((item.get('last_updated', '') for item in analytics), default='')
            }
            
            return summary
            
        except Exception as e:
            logger.error(f"ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚µãƒãƒªãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}


# ä¾¿åˆ©é–¢æ•°
def parse_csv_file(file_path: str, data_source: Optional[str] = None) -> Tuple[bool, Dict[str, Any]]:
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
    parser = EnhancedCSVParser()
    
    with open(file_path, 'rb') as f:
        content = f.read()
    
    return parser.parse_csv_to_database(content, file_path, data_source)


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    print("=== æ–°CSVãƒ‘ãƒ¼ã‚µãƒ¼ãƒ†ã‚¹ãƒˆ ===")
    
    parser = EnhancedCSVParser(DatabaseManager("test_enhanced_parser.db"))
    
    # æ—¢å­˜ã®ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ†ã‚¹ãƒˆ
    test_files = [
        "../assetbalance(JP)_20250626_193110.csv",
        "../New_file 2.csv"
    ]
    
    for file_path in test_files:
        try:
            with open(file_path, 'rb') as f:
                content = f.read()
            
            success, result = parser.parse_csv_to_database(content, file_path)
            
            if success:
                print(f"âœ… {file_path}: {result['success_count']}ä»¶å‡¦ç†æˆåŠŸ")
                print(f"   ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {result['data_source']}")
            else:
                print(f"âŒ {file_path}: å‡¦ç†å¤±æ•— - {result.get('error', 'Unknown error')}")
                
        except FileNotFoundError:
            print(f"âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
    
    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    summary = parser.get_portfolio_summary()
    if "error" not in summary:
        print(f"\nğŸ“Š ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚µãƒãƒªãƒ¼:")
        print(f"   ç·éŠ˜æŸ„æ•°: {summary['total_holdings']}")
        print(f"   ç·è©•ä¾¡é¡: Â¥{summary['total_market_value']:,.0f}")
        print(f"   ç·æç›Š: Â¥{summary['total_profit_loss']:,.0f}")
        print(f"   æç›Šç‡: {summary['profit_loss_rate']:.1f}%")